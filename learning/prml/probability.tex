\documentclass[a4paper]{article}
\usepackage{xeCJK}
\setCJKmainfont[BoldFont={WenQuanYi Zen Hei}, ItalicFont={WenQuanYi Zen Hei}]{WenQuanYi Zen Hei Mono}
%\usepackage{xeCJK}
%\setCJKmainfont{STFangsong}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[sc,osf,slantedGreek]{mathpazo}
\begin{document}
\title{Probability Distributions}
\author{}
\maketitle

The SVM is a decision machine and so does not provide posterior probabilities.
\section{二元变量(Binary Variables)}
$x \in \{0,1\}, p(x=1|\mu) = \mu, p(x=0|\mu) = 1-\mu$, Bernoulli distribution $Bern(x|\mu) = \mu^x(1-\mu)^{1-x}$
data set $D = {x_1,...,x_n}$ of observed values of x. likehood function
\begin{align}
p(D|\mu) = \prod_{n=1}^N p(x_n|\mu) = \prod_{n=1}^N \mu^{x_n}(1-\mu)^{1-x_n}\\
ln p(D|\mu) = \sum_{n=1}^N \{ x_nln\mu + (1-x_n)ln(1-\mu) \}
\end{align}
binomial distribution
\begin{align}
  Bin(m|N,\mu) = {N \choose m} \mu^m (1-\mu)^{N-m}
\end{align}

\subsection{Beta Distribution}

Introduce a prior distribution p(μ)
\begin{align}
  Beta(\mu|a,b) = \frac{ \Gamma(a+b) } {\Gamma(a)\Gamma(b)} \mu^{a-1} (1-\mu)^{b-1}\\
  \Gamma(t) = \int_0^{inf} x^{t-1}e^{-x} dx\\
  \int_0^1 Beta(\mu|a,b) d\mu = 1\\
  \mathbb{E}[\mu] = \frac{a}{a+b}\\
  var[\mu] = \frac{ab}{(a+b)^2(a+b+1)}
\end{align}

Posterior distribution of $\mu$ is now obtained by multiplying the beta prior by the binomial likelihood function

\begin{align*}
  p(\mu|m,l,a,b) &\propto \mu^{m+a-1} (1-\mu)^{l+b-1}\\
  p(\mu|m,l,a,b) &=  \frac{ \Gamma(m+a+l+b) } {\Gamma(m+a)\Gamma(l+b)} \mu^{m+a-1} (1-\mu)^{l+b-1}
\end{align*}
a and b in the prior as an \textit{effective number of observations} of x = 1 and x = 0

\section{Multinomial Variables}
用参数$\mu_k$表示$x_k=1$的概率，$\mathbf{x}$的分布如下：
\begin{align*}
  \mathbf{x} = (0,0,1,0,0,0)^T\\
  p(\mathbf{x}|\mu) = \prod_{k=1}^K\mu_k^{x_k}
\end{align*}
$N$个独立观测值$\mathbf{x_1},...,\mathbf{x_n}$的数据集$D$
\begin{align*}
  p(D|\mu) = \prod_{n=1}^N  \prod_{k=1}^K \mu_k^{x_{nk}} = \prod_{k=1}^K \mu_k^{m_k}\\
  m_k = \sum_n x_{nk}
\end{align*}
$m_k$表示观测到$x_k=1$的次数，这被称为这个分布的充分统计量（sufficient statistics）
多项式分布(multinomial distribution)
\begin{align*}
  Mult(m_1,m_2,...,m_K|\mu,N) = {N \choose m_1m_2...m_K} \prod_{k=1}^K \mu_k^{m_k}\\
  \sum_{k=1}^K m_k = N
\end{align*}
共轭先验为：
\begin{align*}
  Dir(\mu|\alpha) &= \frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1)...\Gamma(\alpha_K)} \prod_{k=1}^K \mu_k^{m_k}\\
\alpha_0 &= \sum \alpha_k
\end{align*}
似然函数乘以先验，得到参数${\mu_k}$的后验概率
\begin{align*}
  p(\mu|D,\alpha) = Dir(\mu|\alpha+\mathbf{m}) = \frac{\Gamma(\alpha_0+N)}{\Gamma(\alpha_1+m_1)...\Gamma(\alpha_K+m_K)} \prod_{k=1}^K \mu_k^{\alpha_k+m_k-1}
\end{align*}
$\alpha_k$看作$x_k=1$的有效观测数。

\section{高斯分布}
\begin{align*}
  \mathcal{N}(x|\mu,\sigma^2) &= \frac{1}{(2\pi\sigma^2)^{1/2}} exp \{-\frac{1}{2\sigma^2} (x-\mu)^2\}\\
  \mathcal{N}(\mathbf{x}|\boldsymbol{\mu},\boldsymbol{\Sigma}) &= \frac{1}{(2\pi)^{D/2}} \frac{1}{|\Sigma|^{1/2}} exp \{-\frac{1}{2} (x-\mu)^T \Sigma^{-1} (x-\mu) \}\\
  \Delta^2 &= (x-\mu)^T \Sigma^{-1} (x-\mu)
\end{align*}

\subsection{Conditional Gaussian distributions}
\begin{align*}
  \boldsymbol{x} =
    \begin{pmatrix} \boldsymbol{x}_a\\ \boldsymbol{x}_b \end{pmatrix},
  \boldsymbol{\mu} =
    \begin{pmatrix} \boldsymbol{\mu}_a\\ \boldsymbol{\mu}_b \end{pmatrix},
  \boldsymbol{\Sigma} =
    \begin{pmatrix}
      \boldsymbol{\Sigma}_{aa} & \boldsymbol{\Sigma}_{ab}\\
      \boldsymbol{\Sigma}_{ba} & \boldsymbol{\Sigma}_{bb}
    \end{pmatrix}
\end{align*}
协方差矩阵的对称性$\Sigma = \Sigma^T$表明$\Sigma_{aa}, \Sigma_{bb}$也是对称的，$\Sigma_{ab}^T=\Sigma_{ba}$.引入精度矩阵：$\Lambda = \Sigma^{-1}$
\begin{align*}
  \boldsymbol{\Lambda} =
    \begin{pmatrix}
      \boldsymbol{\Lambda}_{aa} & \boldsymbol{\Lambda}_{ab}\\
      \boldsymbol{\Lambda}_{ba} & \boldsymbol{\Lambda}_{bb}
    \end{pmatrix}
\end{align*}

寻找条件概率$p(\boldsymbol{x}_a|\boldsymbol{x}_b)$，用精度矩阵展开二次型$\Delta^2$
$p(\boldsymbol{x}_a|\boldsymbol{x}_b)$也是高斯分布，确定其均值与协方差
选出与$x_a$相关的二阶项，得到方差
\begin{align*}
  -\frac{1}{2} \boldsymbol{x}_a^T \boldsymbol{\Lambda}_{aa} \boldsymbol{x}_a
  \Sigma_{a|b} = \Lambda_{aa}^{-1}
\end{align*}
选出与$x_a$相关的线性项，all of the terms that are linear in $x_a$
\begin{align*}
  x_a^T\{ \Lambda_{aa}\mu_a - \Lambda_{ab}(x_b-\mu_b) \}\\
  \mu_{a|b} &= \Sigma_{a|b} \{ \Lambda_{aa}\mu_a - \Lambda_{ab}(x_b-\mu_b) \}\\
         &=  \mu_a - \Lambda_{aa}^{-1}\Lambda_{ab}(x_b - \mu_b)
\end{align*}

\subsection{Marginal Gaussian distributions}
$p(x_a) = \int p(x_a,x_b) dx_b$
注意力集中于联合分布的指数项的二次型
\begin{align*}
  \mathbb{E}[x_a] &= \mu_a\\
  var[x_a] &= \Sigma_{aa}
\end{align*}


分块高斯的边缘分布条件分布总结，给定联合高斯分布$\mathcal{N}(\mathbf{x}|\boldsymbol{\mu},\boldsymbol{\Sigma})$
\begin{align*}
  \boldsymbol{x} =
    \begin{pmatrix} \boldsymbol{x}_a\\ \boldsymbol{x}_b \end{pmatrix},
  \boldsymbol{\mu} =
    \begin{pmatrix} \boldsymbol{\mu}_a\\ \boldsymbol{\mu}_b \end{pmatrix}\\
  \boldsymbol{\Sigma} =
    \begin{pmatrix}
      \boldsymbol{\Sigma}_{aa} & \boldsymbol{\Sigma}_{ab}\\
      \boldsymbol{\Sigma}_{ba} & \boldsymbol{\Sigma}_{bb}
    \end{pmatrix},
  \boldsymbol{\Lambda} =
    \begin{pmatrix}
      \boldsymbol{\Lambda}_{aa} & \boldsymbol{\Lambda}_{ab}\\
      \boldsymbol{\Lambda}_{ba} & \boldsymbol{\Lambda}_{bb}
    \end{pmatrix}
\end{align*}
条件概率分布
\begin{align*}
  p(x_a|x_b) &= \mathcal{N}(\mathbf{x_a}|\boldsymbol{\mu}_{a|b},\boldsymbol{\Lambda}_{aa}^{-1})\\
  \mu_{a|b}  &=  \mu_a - \Lambda_{aa}^{-1}\Lambda_{ab}(x_b - \mu_b)
\end{align*}
边缘概率分布
\begin{align*}
  p(x_a) &= \mathcal{N}(\mathbf{x_a}|\boldsymbol{\mu}_a,\boldsymbol{\Sigma}_{aa})
\end{align*}

\subsection{Bayes’ theorem for Gaussian variables}
\label{sec:2.3.3}

给定一个高斯边缘分布$p(x)$和一个高斯条件分布$p(y | x)$, 其中$p(y | x)$的均值是$x$的线性函数,协方差与$x$无关, 我们想找到边缘概率分布$p(y)$和条件概率分布$p(x|y)$
令边缘概率分布和条件概率分布：
\begin{align}
  p(\boldsymbol{x}) &= \mathcal{N}(\boldsymbol{x}|\boldsymbol{\mu},\boldsymbol{\Lambda}^{-1})\\
  p(\boldsymbol{y}|\boldsymbol{x}) &= \mathcal{N}(\boldsymbol{y}|\boldsymbol{Ax}+\boldsymbol{b},\b
oldsymbol{L}^{-1})
\end{align}
$x$和$y$的维度分别是M和D，则矩阵A的维度是$D \times M$.
考虑$x$和$y$的联合分布
$\boldsymbol{z} = \begin{pmatrix} \boldsymbol{x}\\ \boldsymbol{y} \end{pmatrix}$

\begin{align*}\label{eq:lnpz}
  ln p(z) &= ln p(x) + ln p(y) \\
  &= -{1 \over 2}(\boldsymbol{x}-\boldsymbol{\mu}^T)\boldsymbol{\Lambda}(\boldsymbol{x}-\boldsymbol{\mu})\\
  &= -{1 \over 2}(\boldsymbol{y-Ax-b})^T\boldsymbol{L}(\boldsymbol{y-Ax-b}) + const
\end{align*}

$p(z)$是一个高斯分布，为了找到这个高斯的精度，考虑公式\ref{eq:lnpz}的二阶项
\begin{align*}
-{1 \over 2}\boldsymbol{x}^T(\boldsymbol{\Lambda}+\boldsymbol{A^TLA})\boldsymbol{x} - {1 \over 2}\boldsymbol{y}^T\boldsymbol{Ly} + {1 \over 2}\boldsymbol{y}^T\boldsymbol{LAx} + {1 \over 2}\boldsymbol{x}^T\boldsymbol{A}^T\boldsymbol{Ly} = -{1 \over 2} z^T\boldsymbol{R}z\\
\boldsymbol{R} =
  \begin{pmatrix}
    \boldsymbol{\Lambda}+\boldsymbol{A^TLA} & - \boldsymbol{A}^T\boldsymbol{L}\\
   -\boldsymbol{LA} & \boldsymbol{L}
  \end{pmatrix}
\end{align*}
找到$z$的高斯分布mean:
\begin{align}
  \mathbb{E}[z] =  \begin{pmatrix}
    \boldsymbol{\mu}\\ \boldsymbol{A\mu}+\boldsymbol{b} \end{pmatrix}\\
  \mathbb{E}[y] = \boldsymbol{A\mu}+\boldsymbol{b}\\
  cov[y] = \boldsymbol{L}^{-1}+\boldsymbol{A}\Lambda^{-1}\boldsymbol{A}^T
\end{align}
给定$p(x), p(y|x)$，$y$的边缘分布及给定$y$的条件下$x$的条件概率为：
\begin{align}
  p(y) = \mathcal{N}(y|A\mu+b,L^{-1}+A\Lambda^{-1}A^T)\\
  p(x|y) = \mathcal{N}(x|\Sigma\{ A^TL(y-b)+\Lambda\mu \}, \Sigma)\\
  \Sigma = (\Lambda+A^TLA)^{-1}
\end{align}

\subsection{Maximum likelihood for the Gaussian}
\begin{align}
  \mu_{ML} = {1 \over N} \sum_{n=1}^N x_n\\
  \Sigma_{ML} = {1 \over N} \sum_{n=1}^N (x_n-\mu_{ML})(x_n-\mu_{ML})^T\\
  \mathbb{E}[\mu_{ML}] = \mu\\
  \mathbb{E}[\Sigma_{ML}] = {N-1 \over N} \Sigma
\end{align}

\subsection{Sequential estimation}
Robbins-Monro 算法
考虑随机变量$\theta$ and $z$,它们以联合概率分布$p(\theta,z)$控制。已知$\theta$，$z$的条件分布定义为一个确定的函数$f(\theta)$, called \textit{regression functions}
\begin{align}
  f(\theta) \equiv \mathbb{E}[z|\theta] = \int zp(z|\theta)dz
\end{align}

Goal: find root $\theta^*$ s.t. $f(\theta^*) = 0$
\begin{align}
  \theta^{(N)} = \theta^{(N-1)} + \alpha_{N-1} z(\theta^{(N-1)})
\end{align}
where $z(\theta^{(N)})$ is an observed value of $z$ when $\theta$ takes the value $\theta^{(N)}$. $\{\alpha_N\}$ satisfy the conditions:
\begin{align*}
\lim_{N \to \infty} \alpha_N = 0\\
\sum_{N=1}^\infty \alpha_N = \infty\\
\sum_{N=1}^\infty \alpha_N^2 < \infty\\
\end{align*}

\subsection{Bayesian inference for the Gaussian}
\label{sec:2.3.6}
The maximum likelihood framework gave point estimates for the parameters $\mu$ and $\Sigma$.

mean is known, infer the variance $\sigma^2$. $ \lambda \equiv 1/\sigma^2 $ likelihood function for $\lambda$ takes the form
\begin{align}
  p(\mathbf{X}|\lambda) = \prod \mathcal{N}(x_n|\mu,\lambda^{-1}) \propto \lambda^{N/2} exp \{ -{\lambda \over 2} \sum (x_n-\mu)^2 \}
\end{align}
conjugate prior is \textit{gamma} distribution given by:
\begin{align}
  Gam(\lambda|a,b) = {1 \over \Gamma(a)} b^a\lambda^{a-1}exp(-b\lambda)\\
  \mathtt{E}[\lambda] = {a \over b},\,\,var[\lambda] = {a \over b^2}
\end{align}

...

\subsection{Student’s t-distribution}

\subsection{Periodic variables}

\subsection{Mixtures of Gaussians}
\label{sec:2.3.8}

\section{The Exponential Family}
\label{sec:2.4}

\section{Nonparametric Methods}
\label{sec:2.5}
consider some nonparametric approaches to density estimation that make few assumptions about the form of the distribution.

\subsection{Kernel density estimators}
\label{sec:2.5.1}
假设观测服从$D$维空间的某个末知概率密度$p(x)$,概率质量(probability mass)
\begin{align}
  P = \int_R p(x)dx
\end{align}
N次观测，位于区域$R$的数据点总数为$K$将服从二项分布
\begin{align}
  Bin(K|N,P) = {N \choose K} P^K(1-P)^{N-K}\\
  K \simeq NP\\
  P \simeq p(x)V\\
  p(x) = {K \over NV}
\end{align}
ﬁx $K$ determine $V$ \textit{K-nearest-neighbour}
ﬁx $V$ determine $K$ \textit{kernel} approach

区域$R$取定义为以$x$为中心的小超立方体,为了统计落在区域内的数据点的数量$K$,定义如下函数：
\begin{align}
  k(\mathbf{u}) =
  \begin{cases}
    1,\, |u_i| <= 1/2, i = 1,...,D\\
    0,\, otherwise
  \end{cases}
\end{align}
$k(u)$ is an example of a \textit{kernel function}

\begin{align}
  K = \sum k({x-x_n \over h})\\
  p(x) = {1 \over N} \sum {1 \over h^D} k({x-x_n \over h})
\end{align}
$V = h^D$ the volume of the hypercube of side $h$ in $D$ dimension

Gaussian kernel
\begin{align}
  p(x) = {1 \over N} \sum {1 \over (2 \pi h^2)^{1/2}} exp({- {\|x-x_n\|^2 \over 2h^2 }})
\end{align}


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
